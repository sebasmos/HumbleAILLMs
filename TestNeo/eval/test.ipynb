{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7026106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'simple-evals'...\n",
      "remote: Enumerating objects: 296, done.\u001b[K\n",
      "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
      "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
      "remote: Total 296 (delta 161), reused 122 (delta 122), pack-reused 78 (from 2)\u001b[K\n",
      "Receiving objects: 100% (296/296), 161.25 KiB | 1.00 MiB/s, done.\n",
      "Resolving deltas: 100% (169/169), done.\n",
      "Requirement already satisfied: openai in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (1.102.0)\n",
      "Requirement already satisfied: human-eval in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: fire in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from human-eval) (0.7.1)\n",
      "Requirement already satisfied: numpy in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from human-eval) (2.1.3)\n",
      "Requirement already satisfied: termcolor in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from fire->human-eval) (3.1.0)\n",
      "\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: trl>=0.20.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: peft>=0.17.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: transformers>=4.55.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (4.55.4)\n",
      "Requirement already satisfied: trackio in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (0.2.9)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from trl>=0.20.0) (1.10.1)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from trl>=0.20.0) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from peft>=0.17.0) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from peft>=0.17.0) (24.2)\n",
      "Requirement already satisfied: psutil in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from peft>=0.17.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from peft>=0.17.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from peft>=0.17.0) (2.8.0)\n",
      "Requirement already satisfied: tqdm in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from peft>=0.17.0) (4.67.1)\n",
      "Requirement already satisfied: safetensors in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from peft>=0.17.0) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from peft>=0.17.0) (0.34.4)\n",
      "Requirement already satisfied: filelock in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from transformers>=4.55.0) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from transformers>=4.55.0) (2025.7.34)\n",
      "Requirement already satisfied: requests in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from transformers>=4.55.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from transformers>=4.55.0) (0.21.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft>=0.17.0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft>=0.17.0) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft>=0.17.0) (1.1.9)\n",
      "Requirement already satisfied: gradio<6.0.0,>=5.43.1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from trackio) (5.44.0)\n",
      "Requirement already satisfied: pandas<3.0.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from trackio) (2.3.0)\n",
      "Requirement already satisfied: pillow<12.0.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from trackio) (11.3.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (4.9.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.116.1)\n",
      "Requirement already satisfied: ffmpy in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.12.1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (1.12.1)\n",
      "Requirement already satisfied: groovy~=0.1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.27.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (3.11.3)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (2.11.7)\n",
      "Requirement already satisfied: pydub in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.12.11)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.47.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.16.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio<6.0.0,>=5.43.1->trackio) (0.35.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from gradio-client==1.12.1->gradio<6.0.0,>=5.43.1->trackio) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<6.0.0,>=5.43.1->trackio) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<6.0.0,>=5.43.1->trackio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<6.0.0,>=5.43.1->trackio) (1.3.1)\n",
      "Requirement already satisfied: certifi in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio<6.0.0,>=5.43.1->trackio) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from httpx<1.0,>=0.24.1->gradio<6.0.0,>=5.43.1->trackio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio<6.0.0,>=5.43.1->trackio) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pandas<3.0.0->trackio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pandas<3.0.0->trackio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pandas<3.0.0->trackio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio<6.0.0,>=5.43.1->trackio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio<6.0.0,>=5.43.1->trackio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio<6.0.0,>=5.43.1->trackio) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<6.0.0,>=5.43.1->trackio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<6.0.0,>=5.43.1->trackio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<6.0.0,>=5.43.1->trackio) (14.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from datasets>=3.0.0->trl>=0.20.0) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from datasets>=3.0.0->trl>=0.20.0) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from datasets>=3.0.0->trl>=0.20.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from datasets>=3.0.0->trl>=0.20.0) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.20.0) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.20.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.20.0) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.20.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.20.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.20.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.20.0) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.20.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.20.0) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0->trackio) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from requests->transformers>=4.55.0) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from requests->transformers>=4.55.0) (2.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0.0,>=5.43.1->trackio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0.0,>=5.43.1->trackio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0.0,>=5.43.1->trackio) (0.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.17.0) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from triton==3.4.0->torch>=1.13.0->peft>=0.17.0) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft>=0.17.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: anthropic in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (0.64.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anthropic) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anthropic) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anthropic) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anthropic) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/openai/simple-evals.git\n",
    "!pip install openai human-eval\n",
    "!pip install -q --upgrade torch\n",
    "!pip install -q transformers triton==3.4 kernels\n",
    "!pip uninstall -q torchvision torchaudio -y\n",
    "%pip install \"trl>=0.20.0\" \"peft>=0.17.0\" \"transformers>=4.55.0\" trackio\n",
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33b90bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vgdataia01/f00013545@FVL.LOCAL/miniconda3/envs/felipe/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UEUDAS-ENHANCED HEALTHBENCH EVALUATION\n",
      "Model: gpt-neo-1.3b | Dataset: eval | Max Examples: 500\n",
      "============================================================\n",
      "Loading gpt-neo-1.3b (EleutherAI/gpt-neo-1.3B)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 08:12:22.275143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756991542.318471    4214 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756991542.333622    4214 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756991542.370112    4214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756991542.370138    4214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756991542.370143    4214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756991542.370147    4214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-04 08:12:22.379951: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded gpt-neo-1.3b\n",
      "Downloading eval dataset...\n",
      "Successfully loaded 5000 examples from eval dataset\n",
      "\n",
      "--- BASELINE ---\n",
      "Evaluating 500 examples with Baseline framework...\n",
      "  - Example 1/500\n",
      "  - Example 2/500\n",
      "  - Example 3/500\n",
      "  - Example 4/500\n",
      "  - Example 5/500\n",
      "  - Example 6/500\n",
      "  - Example 7/500\n",
      "  - Example 8/500\n",
      "  - Example 9/500\n",
      "  - Example 10/500\n",
      "  - Example 11/500\n",
      "  - Example 12/500\n",
      "  - Example 13/500\n",
      "  - Example 14/500\n",
      "  - Example 15/500\n",
      "  - Example 16/500\n",
      "  - Example 17/500\n",
      "  - Example 18/500\n",
      "  - Example 19/500\n",
      "  - Example 20/500\n",
      "  - Example 21/500\n",
      "  - Example 22/500\n",
      "  - Example 23/500\n",
      "  - Example 24/500\n",
      "  - Example 25/500\n",
      "  - Example 26/500\n",
      "  - Example 27/500\n",
      "  - Example 28/500\n",
      "  - Example 29/500\n",
      "  - Example 30/500\n",
      "  - Example 31/500\n",
      "  - Example 32/500\n",
      "  - Example 33/500\n",
      "  - Example 34/500\n",
      "  - Example 35/500\n",
      "  - Example 36/500\n",
      "  - Example 37/500\n",
      "  - Example 38/500\n",
      "  - Example 39/500\n",
      "  - Example 40/500\n",
      "  - Example 41/500\n",
      "  - Example 42/500\n",
      "  - Example 43/500\n",
      "  - Example 44/500\n",
      "  - Example 45/500\n",
      "  - Example 46/500\n",
      "  - Example 47/500\n",
      "  - Example 48/500\n",
      "  - Example 49/500\n",
      "  - Example 50/500\n",
      "  - Example 51/500\n",
      "  - Example 52/500\n",
      "  - Example 53/500\n",
      "  - Example 54/500\n",
      "  - Example 55/500\n",
      "  - Example 56/500\n",
      "  - Example 57/500\n",
      "  - Example 58/500\n",
      "  - Example 59/500\n",
      "  - Example 60/500\n",
      "  - Example 61/500\n",
      "  - Example 62/500\n",
      "  - Example 63/500\n",
      "  - Example 64/500\n",
      "  - Example 65/500\n",
      "  - Example 66/500\n",
      "  - Example 67/500\n",
      "  - Example 68/500\n",
      "  - Example 69/500\n",
      "  - Example 70/500\n",
      "  - Example 71/500\n",
      "  - Example 72/500\n",
      "  - Example 73/500\n",
      "  - Example 74/500\n",
      "  - Example 75/500\n",
      "  - Example 76/500\n",
      "  - Example 77/500\n",
      "  - Example 78/500\n",
      "  - Example 79/500\n",
      "  - Example 80/500\n",
      "  - Example 81/500\n",
      "  - Example 82/500\n",
      "  - Example 83/500\n",
      "  - Example 84/500\n",
      "  - Example 85/500\n",
      "  - Example 86/500\n",
      "  - Example 87/500\n",
      "  - Example 88/500\n",
      "  - Example 89/500\n",
      "  - Example 90/500\n",
      "  - Example 91/500\n",
      "  - Example 92/500\n",
      "  - Example 93/500\n",
      "  - Example 94/500\n",
      "  - Example 95/500\n",
      "  - Example 96/500\n",
      "  - Example 97/500\n",
      "  - Example 98/500\n",
      "  - Example 99/500\n",
      "  - Example 100/500\n",
      "  - Example 101/500\n",
      "  - Example 102/500\n",
      "  - Example 103/500\n",
      "  - Example 104/500\n",
      "  - Example 105/500\n",
      "  - Example 106/500\n",
      "  - Example 107/500\n",
      "  - Example 108/500\n",
      "  - Example 109/500\n",
      "  - Example 110/500\n",
      "  - Example 111/500\n",
      "  - Example 112/500\n",
      "  - Example 113/500\n",
      "  - Example 114/500\n",
      "  - Example 115/500\n",
      "  - Example 116/500\n",
      "  - Example 117/500\n",
      "  - Example 118/500\n",
      "  - Example 119/500\n",
      "  - Example 120/500\n",
      "  - Example 121/500\n",
      "  - Example 122/500\n",
      "  - Example 123/500\n",
      "  - Example 124/500\n",
      "  - Example 125/500\n",
      "  - Example 126/500\n",
      "  - Example 127/500\n",
      "  - Example 128/500\n",
      "  - Example 129/500\n",
      "  - Example 130/500\n",
      "  - Example 131/500\n",
      "  - Example 132/500\n",
      "  - Example 133/500\n",
      "  - Example 134/500\n",
      "  - Example 135/500\n",
      "  - Example 136/500\n",
      "  - Example 137/500\n",
      "  - Example 138/500\n",
      "  - Example 139/500\n",
      "  - Example 140/500\n",
      "  - Example 141/500\n",
      "  - Example 142/500\n",
      "  - Example 143/500\n",
      "  - Example 144/500\n",
      "  - Example 145/500\n",
      "  - Example 146/500\n",
      "  - Example 147/500\n",
      "  - Example 148/500\n",
      "  - Example 149/500\n",
      "  - Example 150/500\n",
      "  - Example 151/500\n",
      "  - Example 152/500\n",
      "  - Example 153/500\n",
      "  - Example 154/500\n",
      "  - Example 155/500\n",
      "  - Example 156/500\n",
      "  - Example 157/500\n",
      "  - Example 158/500\n",
      "  - Example 159/500\n",
      "  - Example 160/500\n",
      "  - Example 161/500\n",
      "  - Example 162/500\n",
      "  - Example 163/500\n",
      "  - Example 164/500\n",
      "  - Example 165/500\n",
      "  - Example 166/500\n",
      "  - Example 167/500\n",
      "  - Example 168/500\n",
      "  - Example 169/500\n",
      "  - Example 170/500\n",
      "  - Example 171/500\n",
      "  - Example 172/500\n",
      "  - Example 173/500\n",
      "  - Example 174/500\n",
      "  - Example 175/500\n",
      "  - Example 176/500\n",
      "  - Example 177/500\n",
      "  - Example 178/500\n",
      "  - Example 179/500\n",
      "  - Example 180/500\n",
      "  - Example 181/500\n",
      "  - Example 182/500\n",
      "  - Example 183/500\n",
      "  - Example 184/500\n",
      "  - Example 185/500\n",
      "  - Example 186/500\n",
      "  - Example 187/500\n",
      "  - Example 188/500\n",
      "  - Example 189/500\n",
      "  - Example 190/500\n",
      "  - Example 191/500\n",
      "  - Example 192/500\n",
      "  - Example 193/500\n",
      "  - Example 194/500\n",
      "  - Example 195/500\n",
      "  - Example 196/500\n",
      "  - Example 197/500\n",
      "  - Example 198/500\n",
      "  - Example 199/500\n",
      "  - Example 200/500\n",
      "  - Example 201/500\n",
      "  - Example 202/500\n",
      "  - Example 203/500\n",
      "  - Example 204/500\n",
      "  - Example 205/500\n",
      "  - Example 206/500\n",
      "  - Example 207/500\n",
      "  - Example 208/500\n",
      "  - Example 209/500\n",
      "  - Example 210/500\n",
      "  - Example 211/500\n",
      "  - Example 212/500\n",
      "  - Example 213/500\n",
      "  - Example 214/500\n",
      "  - Example 215/500\n",
      "  - Example 216/500\n",
      "  - Example 217/500\n",
      "  - Example 218/500\n",
      "  - Example 219/500\n",
      "  - Example 220/500\n",
      "  - Example 221/500\n",
      "  - Example 222/500\n",
      "  - Example 223/500\n",
      "  - Example 224/500\n",
      "  - Example 225/500\n",
      "  - Example 226/500\n",
      "  - Example 227/500\n",
      "  - Example 228/500\n",
      "  - Example 229/500\n",
      "  - Example 230/500\n",
      "  - Example 231/500\n",
      "  - Example 232/500\n",
      "  - Example 233/500\n",
      "  - Example 234/500\n",
      "  - Example 235/500\n",
      "  - Example 236/500\n",
      "  - Example 237/500\n",
      "  - Example 238/500\n",
      "  - Example 239/500\n",
      "  - Example 240/500\n",
      "  - Example 241/500\n",
      "  - Example 242/500\n",
      "  - Example 243/500\n",
      "  - Example 244/500\n",
      "  - Example 245/500\n",
      "  - Example 246/500\n",
      "  - Example 247/500\n",
      "  - Example 248/500\n",
      "  - Example 249/500\n",
      "  - Example 250/500\n",
      "  - Example 251/500\n",
      "  - Example 252/500\n",
      "  - Example 253/500\n",
      "  - Example 254/500\n",
      "  - Example 255/500\n",
      "  - Example 256/500\n",
      "  - Example 257/500\n",
      "  - Example 258/500\n",
      "  - Example 259/500\n",
      "  - Example 260/500\n",
      "  - Example 261/500\n",
      "  - Example 262/500\n",
      "  - Example 263/500\n",
      "  - Example 264/500\n",
      "  - Example 265/500\n",
      "  - Example 266/500\n",
      "  - Example 267/500\n",
      "  - Example 268/500\n",
      "  - Example 269/500\n",
      "  - Example 270/500\n",
      "  - Example 271/500\n",
      "  - Example 272/500\n",
      "  - Example 273/500\n",
      "  - Example 274/500\n",
      "  - Example 275/500\n",
      "  - Example 276/500\n",
      "  - Example 277/500\n",
      "  - Example 278/500\n",
      "  - Example 279/500\n",
      "  - Example 280/500\n",
      "  - Example 281/500\n",
      "  - Example 282/500\n",
      "  - Example 283/500\n",
      "  - Example 284/500\n",
      "  - Example 285/500\n",
      "  - Example 286/500\n",
      "  - Example 287/500\n",
      "  - Example 288/500\n",
      "  - Example 289/500\n",
      "  - Example 290/500\n",
      "  - Example 291/500\n",
      "  - Example 292/500\n",
      "  - Example 293/500\n",
      "  - Example 294/500\n",
      "  - Example 295/500\n",
      "  - Example 296/500\n",
      "  - Example 297/500\n",
      "  - Example 298/500\n",
      "  - Example 299/500\n",
      "  - Example 300/500\n",
      "  - Example 301/500\n",
      "  - Example 302/500\n",
      "  - Example 303/500\n",
      "  - Example 304/500\n",
      "  - Example 305/500\n",
      "  - Example 306/500\n",
      "  - Example 307/500\n",
      "  - Example 308/500\n",
      "  - Example 309/500\n",
      "  - Example 310/500\n",
      "  - Example 311/500\n",
      "  - Example 312/500\n",
      "  - Example 313/500\n",
      "  - Example 314/500\n",
      "  - Example 315/500\n",
      "  - Example 316/500\n",
      "  - Example 317/500\n",
      "  - Example 318/500\n",
      "  - Example 319/500\n",
      "  - Example 320/500\n",
      "  - Example 321/500\n",
      "  - Example 322/500\n",
      "  - Example 323/500\n",
      "  - Example 324/500\n",
      "  - Example 325/500\n",
      "  - Example 326/500\n",
      "  - Example 327/500\n",
      "  - Example 328/500\n",
      "  - Example 329/500\n",
      "  - Example 330/500\n",
      "  - Example 331/500\n",
      "  - Example 332/500\n",
      "  - Example 333/500\n",
      "  - Example 334/500\n",
      "  - Example 335/500\n",
      "  - Example 336/500\n",
      "  - Example 337/500\n",
      "  - Example 338/500\n",
      "  - Example 339/500\n",
      "  - Example 340/500\n",
      "  - Example 341/500\n",
      "  - Example 342/500\n",
      "  - Example 343/500\n",
      "  - Example 344/500\n",
      "  - Example 345/500\n",
      "  - Example 346/500\n",
      "  - Example 347/500\n",
      "  - Example 348/500\n",
      "  - Example 349/500\n",
      "  - Example 350/500\n",
      "  - Example 351/500\n",
      "  - Example 352/500\n",
      "  - Example 353/500\n",
      "  - Example 354/500\n",
      "  - Example 355/500\n",
      "  - Example 356/500\n",
      "  - Example 357/500\n",
      "  - Example 358/500\n",
      "  - Example 359/500\n",
      "  - Example 360/500\n",
      "  - Example 361/500\n",
      "  - Example 362/500\n",
      "  - Example 363/500\n",
      "  - Example 364/500\n",
      "  - Example 365/500\n",
      "  - Example 366/500\n",
      "  - Example 367/500\n",
      "  - Example 368/500\n",
      "  - Example 369/500\n",
      "  - Example 370/500\n",
      "  - Example 371/500\n",
      "  - Example 372/500\n",
      "  - Example 373/500\n",
      "  - Example 374/500\n",
      "  - Example 375/500\n",
      "  - Example 376/500\n",
      "  - Example 377/500\n",
      "  - Example 378/500\n",
      "  - Example 379/500\n",
      "  - Example 380/500\n",
      "  - Example 381/500\n",
      "  - Example 382/500\n",
      "  - Example 383/500\n",
      "  - Example 384/500\n",
      "  - Example 385/500\n",
      "  - Example 386/500\n",
      "  - Example 387/500\n",
      "  - Example 388/500\n",
      "  - Example 389/500\n",
      "  - Example 390/500\n",
      "  - Example 391/500\n",
      "  - Example 392/500\n",
      "  - Example 393/500\n",
      "  - Example 394/500\n",
      "  - Example 395/500\n",
      "  - Example 396/500\n",
      "  - Example 397/500\n",
      "  - Example 398/500\n",
      "  - Example 399/500\n",
      "  - Example 400/500\n",
      "  - Example 401/500\n",
      "  - Example 402/500\n",
      "  - Example 403/500\n",
      "  - Example 404/500\n",
      "  - Example 405/500\n",
      "  - Example 406/500\n",
      "  - Example 407/500\n",
      "  - Example 408/500\n",
      "  - Example 409/500\n",
      "  - Example 410/500\n",
      "  - Example 411/500\n",
      "  - Example 412/500\n",
      "  - Example 413/500\n",
      "  - Example 414/500\n",
      "  - Example 415/500\n",
      "  - Example 416/500\n",
      "  - Example 417/500\n",
      "  - Example 418/500\n",
      "  - Example 419/500\n",
      "  - Example 420/500\n",
      "  - Example 421/500\n",
      "  - Example 422/500\n",
      "  - Example 423/500\n",
      "  - Example 424/500\n",
      "  - Example 425/500\n",
      "  - Example 426/500\n",
      "  - Example 427/500\n",
      "  - Example 428/500\n",
      "  - Example 429/500\n",
      "  - Example 430/500\n",
      "  - Example 431/500\n",
      "  - Example 432/500\n",
      "  - Example 433/500\n",
      "  - Example 434/500\n",
      "  - Example 435/500\n",
      "  - Example 436/500\n",
      "  - Example 437/500\n",
      "  - Example 438/500\n",
      "  - Example 439/500\n",
      "  - Example 440/500\n",
      "  - Example 441/500\n",
      "  - Example 442/500\n",
      "  - Example 443/500\n",
      "  - Example 444/500\n",
      "  - Example 445/500\n",
      "  - Example 446/500\n",
      "  - Example 447/500\n",
      "  - Example 448/500\n",
      "  - Example 449/500\n",
      "  - Example 450/500\n",
      "  - Example 451/500\n",
      "  - Example 452/500\n",
      "  - Example 453/500\n",
      "  - Example 454/500\n",
      "  - Example 455/500\n",
      "  - Example 456/500\n",
      "  - Example 457/500\n",
      "  - Example 458/500\n",
      "  - Example 459/500\n",
      "  - Example 460/500\n",
      "  - Example 461/500\n",
      "  - Example 462/500\n",
      "  - Example 463/500\n",
      "  - Example 464/500\n",
      "  - Example 465/500\n",
      "  - Example 466/500\n",
      "  - Example 467/500\n",
      "  - Example 468/500\n",
      "  - Example 469/500\n",
      "  - Example 470/500\n",
      "  - Example 471/500\n",
      "  - Example 472/500\n",
      "  - Example 473/500\n",
      "  - Example 474/500\n",
      "  - Example 475/500\n",
      "  - Example 476/500\n",
      "  - Example 477/500\n",
      "  - Example 478/500\n",
      "  - Example 479/500\n",
      "  - Example 480/500\n",
      "  - Example 481/500\n",
      "  - Example 482/500\n",
      "  - Example 483/500\n",
      "  - Example 484/500\n",
      "  - Example 485/500\n",
      "  - Example 486/500\n",
      "  - Example 487/500\n",
      "  - Example 488/500\n",
      "  - Example 489/500\n",
      "  - Example 490/500\n",
      "  - Example 491/500\n",
      "  - Example 492/500\n",
      "  - Example 493/500\n",
      "  - Example 494/500\n",
      "  - Example 495/500\n",
      "  - Example 496/500\n",
      "  - Example 497/500\n",
      "  - Example 498/500\n",
      "  - Example 499/500\n",
      "  - Example 500/500\n",
      "\n",
      "============================================================\n",
      "BASELINE SUMMARY\n",
      "============================================================\n",
      "Model: gpt-neo-1.3b | Dataset: eval | Type: Baseline\n",
      "Examples: 500\n",
      "Baseline score: 0.485\n",
      "Avg response length (chars): 1026.1\n",
      "Baseline results saved to: ./baseline_gpt-neo-1.3b_eval_20250904_094700.json\n",
      "\n",
      "--- UEUDAS ---\n",
      "Evaluating 500 examples with UEUDAS framework...\n",
      "  - Example 1/500\n",
      "  - Example 2/500\n",
      "  - Example 3/500\n",
      "  - Example 4/500\n",
      "  - Example 5/500\n",
      "  - Example 6/500\n",
      "  - Example 7/500\n",
      "  - Example 8/500\n",
      "  - Example 9/500\n",
      "  - Example 10/500\n",
      "  - Example 11/500\n",
      "  - Example 12/500\n",
      "  - Example 13/500\n",
      "  - Example 14/500\n",
      "  - Example 15/500\n",
      "  - Example 16/500\n",
      "  - Example 17/500\n",
      "  - Example 18/500\n",
      "  - Example 19/500\n",
      "  - Example 20/500\n",
      "  - Example 21/500\n",
      "  - Example 22/500\n",
      "  - Example 23/500\n",
      "  - Example 24/500\n",
      "  - Example 25/500\n",
      "  - Example 26/500\n",
      "  - Example 27/500\n",
      "  - Example 28/500\n",
      "  - Example 29/500\n",
      "  - Example 30/500\n",
      "  - Example 31/500\n",
      "  - Example 32/500\n",
      "  - Example 33/500\n",
      "  - Example 34/500\n",
      "  - Example 35/500\n",
      "  - Example 36/500\n",
      "  - Example 37/500\n",
      "  - Example 38/500\n",
      "  - Example 39/500\n",
      "  - Example 40/500\n",
      "  - Example 41/500\n",
      "  - Example 42/500\n",
      "  - Example 43/500\n",
      "  - Example 44/500\n",
      "  - Example 45/500\n",
      "  - Example 46/500\n",
      "  - Example 47/500\n",
      "  - Example 48/500\n",
      "  - Example 49/500\n",
      "  - Example 50/500\n",
      "  - Example 51/500\n",
      "  - Example 52/500\n",
      "  - Example 53/500\n",
      "  - Example 54/500\n",
      "  - Example 55/500\n",
      "  - Example 56/500\n",
      "  - Example 57/500\n",
      "  - Example 58/500\n",
      "  - Example 59/500\n",
      "  - Example 60/500\n",
      "  - Example 61/500\n",
      "  - Example 62/500\n",
      "  - Example 63/500\n",
      "  - Example 64/500\n",
      "  - Example 65/500\n",
      "  - Example 66/500\n",
      "  - Example 67/500\n",
      "  - Example 68/500\n",
      "  - Example 69/500\n",
      "  - Example 70/500\n",
      "  - Example 71/500\n",
      "  - Example 72/500\n",
      "  - Example 73/500\n",
      "  - Example 74/500\n",
      "  - Example 75/500\n",
      "  - Example 76/500\n",
      "  - Example 77/500\n",
      "  - Example 78/500\n",
      "  - Example 79/500\n",
      "  - Example 80/500\n",
      "  - Example 81/500\n",
      "  - Example 82/500\n",
      "  - Example 83/500\n",
      "  - Example 84/500\n",
      "  - Example 85/500\n",
      "  - Example 86/500\n",
      "  - Example 87/500\n",
      "  - Example 88/500\n",
      "  - Example 89/500\n",
      "  - Example 90/500\n",
      "  - Example 91/500\n",
      "  - Example 92/500\n",
      "  - Example 93/500\n",
      "  - Example 94/500\n",
      "  - Example 95/500\n",
      "  - Example 96/500\n",
      "  - Example 97/500\n",
      "  - Example 98/500\n",
      "  - Example 99/500\n",
      "  - Example 100/500\n",
      "  - Example 101/500\n",
      "  - Example 102/500\n",
      "  - Example 103/500\n",
      "  - Example 104/500\n",
      "  - Example 105/500\n",
      "  - Example 106/500\n",
      "  - Example 107/500\n",
      "  - Example 108/500\n",
      "  - Example 109/500\n",
      "  - Example 110/500\n",
      "  - Example 111/500\n",
      "  - Example 112/500\n",
      "  - Example 113/500\n",
      "  - Example 114/500\n",
      "  - Example 115/500\n",
      "  - Example 116/500\n",
      "  - Example 117/500\n",
      "  - Example 118/500\n",
      "  - Example 119/500\n",
      "  - Example 120/500\n",
      "  - Example 121/500\n",
      "  - Example 122/500\n",
      "  - Example 123/500\n",
      "  - Example 124/500\n",
      "  - Example 125/500\n",
      "  - Example 126/500\n",
      "  - Example 127/500\n",
      "  - Example 128/500\n",
      "  - Example 129/500\n",
      "  - Example 130/500\n",
      "  - Example 131/500\n",
      "  - Example 132/500\n",
      "  - Example 133/500\n",
      "  - Example 134/500\n",
      "  - Example 135/500\n",
      "  - Example 136/500\n",
      "  - Example 137/500\n",
      "  - Example 138/500\n",
      "  - Example 139/500\n",
      "  - Example 140/500\n",
      "  - Example 141/500\n",
      "  - Example 142/500\n",
      "  - Example 143/500\n",
      "  - Example 144/500\n",
      "  - Example 145/500\n",
      "  - Example 146/500\n",
      "  - Example 147/500\n",
      "  - Example 148/500\n",
      "  - Example 149/500\n",
      "  - Example 150/500\n",
      "  - Example 151/500\n",
      "  - Example 152/500\n",
      "  - Example 153/500\n",
      "  - Example 154/500\n",
      "  - Example 155/500\n",
      "  - Example 156/500\n",
      "  - Example 157/500\n",
      "  - Example 158/500\n",
      "  - Example 159/500\n",
      "  - Example 160/500\n",
      "  - Example 161/500\n",
      "  - Example 162/500\n",
      "  - Example 163/500\n",
      "  - Example 164/500\n",
      "  - Example 165/500\n",
      "  - Example 166/500\n",
      "  - Example 167/500\n",
      "  - Example 168/500\n",
      "  - Example 169/500\n",
      "  - Example 170/500\n",
      "  - Example 171/500\n",
      "  - Example 172/500\n",
      "  - Example 173/500\n",
      "  - Example 174/500\n",
      "  - Example 175/500\n",
      "  - Example 176/500\n",
      "  - Example 177/500\n",
      "  - Example 178/500\n",
      "  - Example 179/500\n",
      "  - Example 180/500\n",
      "  - Example 181/500\n",
      "  - Example 182/500\n",
      "  - Example 183/500\n",
      "  - Example 184/500\n",
      "  - Example 185/500\n",
      "  - Example 186/500\n",
      "  - Example 187/500\n",
      "  - Example 188/500\n",
      "  - Example 189/500\n",
      "  - Example 190/500\n",
      "  - Example 191/500\n",
      "  - Example 192/500\n",
      "  - Example 193/500\n",
      "  - Example 194/500\n",
      "  - Example 195/500\n",
      "  - Example 196/500\n",
      "  - Example 197/500\n",
      "  - Example 198/500\n",
      "  - Example 199/500\n",
      "  - Example 200/500\n",
      "  - Example 201/500\n",
      "  - Example 202/500\n",
      "  - Example 203/500\n",
      "  - Example 204/500\n",
      "  - Example 205/500\n",
      "  - Example 206/500\n",
      "  - Example 207/500\n",
      "  - Example 208/500\n",
      "  - Example 209/500\n",
      "  - Example 210/500\n",
      "  - Example 211/500\n",
      "  - Example 212/500\n",
      "  - Example 213/500\n",
      "  - Example 214/500\n",
      "  - Example 215/500\n",
      "  - Example 216/500\n",
      "  - Example 217/500\n",
      "  - Example 218/500\n",
      "  - Example 219/500\n",
      "  - Example 220/500\n",
      "  - Example 221/500\n",
      "  - Example 222/500\n",
      "  - Example 223/500\n",
      "  - Example 224/500\n",
      "  - Example 225/500\n",
      "  - Example 226/500\n",
      "  - Example 227/500\n",
      "  - Example 228/500\n",
      "  - Example 229/500\n",
      "  - Example 230/500\n",
      "  - Example 231/500\n",
      "  - Example 232/500\n",
      "  - Example 233/500\n",
      "  - Example 234/500\n",
      "  - Example 235/500\n",
      "  - Example 236/500\n",
      "  - Example 237/500\n",
      "  - Example 238/500\n",
      "  - Example 239/500\n",
      "  - Example 240/500\n",
      "  - Example 241/500\n",
      "  - Example 242/500\n",
      "  - Example 243/500\n",
      "  - Example 244/500\n",
      "  - Example 245/500\n",
      "  - Example 246/500\n",
      "  - Example 247/500\n",
      "  - Example 248/500\n",
      "  - Example 249/500\n",
      "  - Example 250/500\n",
      "  - Example 251/500\n",
      "  - Example 252/500\n",
      "  - Example 253/500\n",
      "  - Example 254/500\n",
      "  - Example 255/500\n",
      "  - Example 256/500\n",
      "  - Example 257/500\n",
      "  - Example 258/500\n",
      "  - Example 259/500\n",
      "  - Example 260/500\n",
      "  - Example 261/500\n",
      "  - Example 262/500\n",
      "  - Example 263/500\n",
      "  - Example 264/500\n",
      "  - Example 265/500\n",
      "  - Example 266/500\n",
      "  - Example 267/500\n",
      "  - Example 268/500\n",
      "  - Example 269/500\n",
      "  - Example 270/500\n",
      "  - Example 271/500\n",
      "  - Example 272/500\n",
      "  - Example 273/500\n",
      "  - Example 274/500\n",
      "  - Example 275/500\n",
      "  - Example 276/500\n",
      "  - Example 277/500\n",
      "  - Example 278/500\n",
      "  - Example 279/500\n",
      "  - Example 280/500\n",
      "  - Example 281/500\n",
      "  - Example 282/500\n",
      "  - Example 283/500\n",
      "  - Example 284/500\n",
      "  - Example 285/500\n",
      "  - Example 286/500\n",
      "  - Example 287/500\n",
      "  - Example 288/500\n",
      "  - Example 289/500\n",
      "  - Example 290/500\n",
      "  - Example 291/500\n",
      "  - Example 292/500\n",
      "  - Example 293/500\n",
      "  - Example 294/500\n",
      "  - Example 295/500\n",
      "  - Example 296/500\n",
      "  - Example 297/500\n",
      "  - Example 298/500\n",
      "  - Example 299/500\n",
      "  - Example 300/500\n",
      "  - Example 301/500\n",
      "  - Example 302/500\n",
      "  - Example 303/500\n",
      "  - Example 304/500\n",
      "  - Example 305/500\n",
      "  - Example 306/500\n",
      "  - Example 307/500\n",
      "  - Example 308/500\n",
      "  - Example 309/500\n",
      "  - Example 310/500\n",
      "  - Example 311/500\n",
      "  - Example 312/500\n",
      "  - Example 313/500\n",
      "  - Example 314/500\n",
      "  - Example 315/500\n",
      "  - Example 316/500\n",
      "  - Example 317/500\n",
      "  - Example 318/500\n",
      "  - Example 319/500\n",
      "  - Example 320/500\n",
      "  - Example 321/500\n",
      "  - Example 322/500\n",
      "  - Example 323/500\n",
      "  - Example 324/500\n",
      "  - Example 325/500\n",
      "  - Example 326/500\n",
      "  - Example 327/500\n",
      "  - Example 328/500\n",
      "  - Example 329/500\n",
      "  - Example 330/500\n",
      "  - Example 331/500\n",
      "  - Example 332/500\n",
      "  - Example 333/500\n",
      "  - Example 334/500\n",
      "  - Example 335/500\n",
      "  - Example 336/500\n",
      "  - Example 337/500\n",
      "  - Example 338/500\n",
      "  - Example 339/500\n",
      "  - Example 340/500\n",
      "  - Example 341/500\n",
      "  - Example 342/500\n",
      "  - Example 343/500\n",
      "  - Example 344/500\n",
      "  - Example 345/500\n",
      "  - Example 346/500\n",
      "  - Example 347/500\n",
      "  - Example 348/500\n",
      "  - Example 349/500\n",
      "  - Example 350/500\n",
      "  - Example 351/500\n",
      "  - Example 352/500\n",
      "  - Example 353/500\n",
      "  - Example 354/500\n",
      "  - Example 355/500\n",
      "  - Example 356/500\n",
      "  - Example 357/500\n",
      "  - Example 358/500\n",
      "  - Example 359/500\n",
      "  - Example 360/500\n",
      "  - Example 361/500\n",
      "  - Example 362/500\n",
      "  - Example 363/500\n",
      "  - Example 364/500\n",
      "  - Example 365/500\n",
      "  - Example 366/500\n",
      "  - Example 367/500\n",
      "  - Example 368/500\n",
      "  - Example 369/500\n",
      "  - Example 370/500\n",
      "  - Example 371/500\n",
      "  - Example 372/500\n",
      "  - Example 373/500\n",
      "  - Example 374/500\n",
      "  - Example 375/500\n",
      "  - Example 376/500\n",
      "  - Example 377/500\n",
      "  - Example 378/500\n",
      "  - Example 379/500\n",
      "  - Example 380/500\n",
      "  - Example 381/500\n",
      "  - Example 382/500\n",
      "  - Example 383/500\n",
      "  - Example 384/500\n",
      "  - Example 385/500\n",
      "  - Example 386/500\n",
      "  - Example 387/500\n",
      "  - Example 388/500\n",
      "  - Example 389/500\n",
      "  - Example 390/500\n",
      "  - Example 391/500\n",
      "  - Example 392/500\n",
      "  - Example 393/500\n",
      "  - Example 394/500\n",
      "  - Example 395/500\n",
      "  - Example 396/500\n",
      "  - Example 397/500\n",
      "  - Example 398/500\n",
      "  - Example 399/500\n",
      "  - Example 400/500\n",
      "  - Example 401/500\n",
      "  - Example 402/500\n",
      "  - Example 403/500\n",
      "  - Example 404/500\n",
      "  - Example 405/500\n",
      "  - Example 406/500\n",
      "  - Example 407/500\n",
      "  - Example 408/500\n",
      "  - Example 409/500\n",
      "  - Example 410/500\n",
      "  - Example 411/500\n",
      "  - Example 412/500\n",
      "  - Example 413/500\n",
      "  - Example 414/500\n",
      "  - Example 415/500\n",
      "  - Example 416/500\n",
      "  - Example 417/500\n",
      "  - Example 418/500\n",
      "  - Example 419/500\n",
      "  - Example 420/500\n",
      "  - Example 421/500\n",
      "  - Example 422/500\n",
      "  - Example 423/500\n",
      "  - Example 424/500\n",
      "  - Example 425/500\n",
      "  - Example 426/500\n",
      "  - Example 427/500\n",
      "  - Example 428/500\n",
      "  - Example 429/500\n",
      "  - Example 430/500\n",
      "  - Example 431/500\n",
      "  - Example 432/500\n",
      "  - Example 433/500\n",
      "  - Example 434/500\n",
      "  - Example 435/500\n",
      "  - Example 436/500\n",
      "  - Example 437/500\n",
      "  - Example 438/500\n",
      "  - Example 439/500\n",
      "  - Example 440/500\n",
      "  - Example 441/500\n",
      "  - Example 442/500\n",
      "  - Example 443/500\n",
      "  - Example 444/500\n",
      "  - Example 445/500\n",
      "  - Example 446/500\n",
      "  - Example 447/500\n",
      "  - Example 448/500\n",
      "  - Example 449/500\n",
      "  - Example 450/500\n",
      "  - Example 451/500\n",
      "  - Example 452/500\n",
      "  - Example 453/500\n",
      "  - Example 454/500\n",
      "  - Example 455/500\n",
      "  - Example 456/500\n",
      "  - Example 457/500\n",
      "  - Example 458/500\n",
      "  - Example 459/500\n",
      "  - Example 460/500\n",
      "  - Example 461/500\n",
      "  - Example 462/500\n",
      "  - Example 463/500\n",
      "  - Example 464/500\n",
      "  - Example 465/500\n",
      "  - Example 466/500\n",
      "  - Example 467/500\n",
      "  - Example 468/500\n",
      "  - Example 469/500\n",
      "  - Example 470/500\n",
      "  - Example 471/500\n",
      "  - Example 472/500\n",
      "  - Example 473/500\n",
      "  - Example 474/500\n",
      "  - Example 475/500\n",
      "  - Example 476/500\n",
      "  - Example 477/500\n",
      "  - Example 478/500\n",
      "  - Example 479/500\n",
      "  - Example 480/500\n",
      "  - Example 481/500\n",
      "  - Example 482/500\n",
      "  - Example 483/500\n",
      "  - Example 484/500\n",
      "  - Example 485/500\n",
      "  - Example 486/500\n",
      "  - Example 487/500\n",
      "  - Example 488/500\n",
      "  - Example 489/500\n",
      "  - Example 490/500\n",
      "  - Example 491/500\n",
      "  - Example 492/500\n",
      "  - Example 493/500\n",
      "  - Example 494/500\n",
      "  - Example 495/500\n",
      "  - Example 496/500\n",
      "  - Example 497/500\n",
      "  - Example 498/500\n",
      "  - Example 499/500\n",
      "  - Example 500/500\n",
      "\n",
      "============================================================\n",
      "UEUDAS SUMMARY\n",
      "============================================================\n",
      "Model: gpt-neo-1.3b | Dataset: eval | Type: UEUDAS\n",
      "Examples: 500\n",
      "UEUDAS score: 0.860\n",
      "Rubric score component:      0.657\n",
      "EVS component:               0.996\n",
      "Avg response length (chars): 988.5\n",
      "UEUDAS results saved to: ./ueudas_gpt-neo-1.3b_eval_20250904_112251.json\n",
      "\n",
      "Saved figures:\n",
      " - ./baseline_vs_ueudas_gpt-neo-1.3b_eval.png\n",
      " - ./ueudas_components_gpt-neo-1.3b_eval.png\n",
      "\n",
      "============================================================\n",
      "DONE\n",
      "Baseline results: ./baseline_gpt-neo-1.3b_eval_20250904_094700.json\n",
      "UEUDAS results:  ./ueudas_gpt-neo-1.3b_eval_20250904_112251.json\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# HealthBench + UEUDAS/PRECISE-U (EVS INCLUDED)\n",
    "# Baseline (raw) vs UEUDAS (PRECISE-U + EVS)\n",
    "# - Baseline: NO helper instruction, NO schema enforcement\n",
    "# - UEUDAS score = BASIC_WEIGHT * rubric_basic + (1 - BASIC_WEIGHT) * EVS\n",
    "# - Deterministic UEUDAS generation to stabilize numeric fields\n",
    "# - Robust token truncation and file saving\n",
    "# - Clean console output\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "import re\n",
    "import traceback\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.utils import logging as hf_logging\n",
    "\n",
    "# ------------------ Quiet logs ------------------\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "hf_logging.set_verbosity_error()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ------------------ Config ------------------\n",
    "DEFAULT_MAX_NEW_TOKENS = 384\n",
    "DEFAULT_TEMPERATURE = 0.2\n",
    "DEFAULT_REPETITION_PENALTY = 1.08\n",
    "DEFAULT_NO_REPEAT_NGRAM_SIZE = 4\n",
    "DEFAULT_TOP_P = 0.9\n",
    "SAFETY_MARGIN = 32\n",
    "\n",
    "# UEUDAS score blend (EVS is part of UEUDAS)\n",
    "BASIC_WEIGHT = 0.40   # rubric/basic share\n",
    "EVS_WEIGHT   = 0.60   # EVS share\n",
    "\n",
    "# Conservative rubric weights (to target ~0.55 on baseline gpt-neo-1.3B)\n",
    "RUBRIC_WEIGHTS = {\n",
    "    \"base\": 0.40,                 # constant base for a coherent reply\n",
    "    \"structure\": 0.15,            # section structure indicators\n",
    "    \"length\": 0.05,               # within reasonable length\n",
    "    \"safety\": 0.10,               # consult/safety language\n",
    "    \"evidence\": 0.05,             # evidence/clinical/guidelines wording\n",
    "    \"uncertainty_cap\": 0.08,      # uncertainty words cap\n",
    "    \"info_seeking_cap\": 0.07,     # info-seeking words cap\n",
    "    \"emergency\": 0.10,            # recognizes/sees emergency when present\n",
    "    # tiny nudges for explicit numerics in UEUDAS outputs (if present)\n",
    "    \"confidence_nudge\": 0.02,\n",
    "    \"humility_nudge\":   0.01,\n",
    "    \"curiosity_nudge\":  0.01,\n",
    "}\n",
    "\n",
    "# ------------------ Utilities ------------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    try: torch.cuda.manual_seed_all(seed)\n",
    "    except Exception: pass\n",
    "\n",
    "def _choose_out_dir(preferred=\"/mnt/data\"):\n",
    "    try:\n",
    "        os.makedirs(preferred, exist_ok=True)\n",
    "        return preferred\n",
    "    except Exception:\n",
    "        os.makedirs(\".\", exist_ok=True)\n",
    "        return \".\"\n",
    "OUT_DIR = _choose_out_dir(\"/mnt/data\")\n",
    "\n",
    "def _ctx(model, tok, default=2048) -> int:\n",
    "    cfg = getattr(model, \"config\", None)\n",
    "    for k in (\"max_position_embeddings\", \"n_positions\", \"max_sequence_length\"):\n",
    "        if getattr(cfg, k, None):\n",
    "            v = int(getattr(cfg, k))\n",
    "            if 0 < v < 100_000:\n",
    "                return v\n",
    "    ml = getattr(tok, \"model_max_length\", None)\n",
    "    return int(ml) if ml and 0 < int(ml) < 100_000 else int(default)\n",
    "\n",
    "def _chat_to_text(messages: Union[str, List[Dict[str, Any]]]) -> str:\n",
    "    if isinstance(messages, str): return messages.strip()\n",
    "    if isinstance(messages, list):\n",
    "        bits = []\n",
    "        for m in messages:\n",
    "            if not isinstance(m, dict): continue\n",
    "            c = m.get(\"content\", \"\")\n",
    "            if isinstance(c, list):\n",
    "                for part in c:\n",
    "                    if isinstance(part, dict) and part.get(\"type\") == \"text\":\n",
    "                        bits.append(str(part.get(\"text\", \"\")))\n",
    "            elif isinstance(c, str):\n",
    "                bits.append(c)\n",
    "        t = \"\\n\".join([b for b in bits if b]).strip()\n",
    "        return t if t else json.dumps(messages, ensure_ascii=False)\n",
    "    return str(messages)\n",
    "\n",
    "def _extract_between(text: str, start: str, end: str) -> str:\n",
    "    i, j = text.find(start), text.rfind(end)\n",
    "    if i != -1 and j != -1 and j > i:\n",
    "        return text[i + len(start): j].strip()\n",
    "    return text.strip()\n",
    "\n",
    "def _safe_generate(model, tok, prompt_text: str, max_tokens=DEFAULT_MAX_NEW_TOKENS,\n",
    "                   temperature=DEFAULT_TEMPERATURE, deterministic=False,\n",
    "                   repetition_penalty=DEFAULT_REPETITION_PENALTY,\n",
    "                   no_repeat_ngram_size=DEFAULT_NO_REPEAT_NGRAM_SIZE,\n",
    "                   top_p=DEFAULT_TOP_P):\n",
    "    device_used = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    try:\n",
    "        max_ctx = _ctx(model, tok, 2048)\n",
    "        max_input_len = max(1, max_ctx - max_tokens - SAFETY_MARGIN)\n",
    "        enc = tok(prompt_text, return_tensors=\"pt\", truncation=True, max_length=max_input_len)\n",
    "        enc = {k: v.to(model.device) for k, v in enc.items()}\n",
    "        input_len = int(enc[\"input_ids\"].shape[1])\n",
    "\n",
    "        eos = tok.eos_token_id or getattr(getattr(model, \"config\", None), \"eos_token_id\", None) or 50256\n",
    "        gen_kwargs = dict(\n",
    "            max_new_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=bool(temperature and temperature > 0),\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            top_p=top_p,\n",
    "            pad_token_id=tok.eos_token_id or eos,\n",
    "            eos_token_id=eos,\n",
    "        )\n",
    "        if deterministic or temperature == 0:\n",
    "            gen_kwargs.update(dict(do_sample=False, top_k=None, top_p=1.0))\n",
    "            set_seed(42)\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                out = model.generate(input_ids=enc[\"input_ids\"], attention_mask=enc[\"attention_mask\"], **gen_kwargs)\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA error\" in str(e).lower():\n",
    "                device_used = \"cpu_fallback\"\n",
    "                try: torch.cuda.empty_cache()\n",
    "                except Exception: pass\n",
    "                model.to(\"cpu\")\n",
    "                enc = {k: v.to(\"cpu\") for k, v in enc.items()}\n",
    "                with torch.no_grad():\n",
    "                    out = model.generate(input_ids=enc[\"input_ids\"], attention_mask=enc[\"attention_mask\"], **gen_kwargs)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        gen_ids = out[0]\n",
    "        new_tokens = gen_ids[input_len:]\n",
    "        text = tok.decode(new_tokens, skip_special_tokens=True)\n",
    "        return text, {\"prompt_tokens\": input_len, \"completion_tokens\": int(len(new_tokens)),\n",
    "                      \"total_tokens\": int(len(gen_ids)), \"device\": device_used}\n",
    "    except Exception as e:\n",
    "        tb = traceback.format_exc(limit=1)\n",
    "        return f\"Error generating response: {e}\", {\"prompt_tokens\": 0, \"completion_tokens\": 0,\n",
    "                                                  \"total_tokens\": 0, \"device\": device_used,\n",
    "                                                  \"error_type\": type(e).__name__, \"trace\": tb.strip()}\n",
    "\n",
    "# ------------------ UEUDAS core ------------------\n",
    "@dataclass\n",
    "class UEUDASComponents:\n",
    "    u_data: float = 0.0\n",
    "    u_model: float = 0.0\n",
    "    u_ood: float = 0.0\n",
    "    u_struct: float = 0.0\n",
    "    complexity: float = 0.0\n",
    "    confidence: float = 0.0\n",
    "    humility: float = 0.0\n",
    "    curiosity: float = 0.0\n",
    "\n",
    "    @property\n",
    "    def total_uncertainty(self) -> float:\n",
    "        return (0.3*self.u_data + 0.3*self.u_model + 0.2*self.u_ood + 0.2*self.u_struct)\n",
    "\n",
    "    def targets(self) -> Tuple[float, float]:\n",
    "        U, C, M = self.total_uncertainty, self.complexity, self.confidence\n",
    "        h_star = min(1.0, U + C*(1-M))\n",
    "        q_star = U*(1+C)*(1 - M**2)\n",
    "        return h_star, q_star\n",
    "\n",
    "    def evs(self) -> float:\n",
    "        U, C, M = self.total_uncertainty, self.complexity, self.confidence\n",
    "        H, Q = self.humility, self.curiosity\n",
    "        h_star, q_star = self.targets()\n",
    "        hubris = np.exp(-((h_star - H)**2) / max(U, 0.01)) if H < h_star else 1.0\n",
    "        hum_term = np.exp(-((H - h_star)**2) / (2*max(U, 0.01)))\n",
    "        cur_term = np.exp(-((Q - q_star)**2) / (2*max(C*U, 0.01)))\n",
    "        return float(hubris * hum_term * cur_term)\n",
    "\n",
    "class PRECISEUTemplate:\n",
    "    START = \"### START OUTPUT\"\n",
    "    END = \"### END OUTPUT\"\n",
    "    MICRO = (\n",
    "        \"Worked micro-example (format only; not the same case):\\n\"\n",
    "        \"P - Probabilistic differential:\\n\"\n",
    "        \"- Dx A: 40%\\n- Dx B: 30%\\n- Dx C: 20%\\n- Other: 10%\\n\"\n",
    "        \"R - Red flags:\\n- Sudden severe pain; syncope.\\n\"\n",
    "        \"E - Explore uncertainties:\\n- Data: 0.4\\n- Model: 0.3\\n- OOD: 0.2\\n- Structural: 0.1\\n\"\n",
    "        \"C - Calculate confidence:\\n- Confidence: 60%\\n\"\n",
    "        \"Complexity: 0.6\\n\"\n",
    "        \"Targets (computed): H* = min(1, U + C*(1-M)); Q* = U*(1+C)*(1-M^2)\\n\"\n",
    "        \"Totals \u0014 U: 0.34 | C: 0.60 | M: 0.60\\n\"\n",
    "        \"Targets \u0014 H*: 0.76 | Q*: 0.54\\n\"\n",
    "        \"Humility: 0.76\\nCuriosity: 0.54\\n\"\n",
    "        \"--- End example ---\\n\"\n",
    "    )\n",
    "\n",
    "    @staticmethod\n",
    "    def select_prompts(uprof: Dict[str, float]) -> List[str]:\n",
    "        lib = {\n",
    "            'u_data': [\"Missing critical data; quantify impact.\", \"Pending labs; show probability shifts.\"],\n",
    "            'u_model': [\"Guideline disagreement; reason across frameworks.\", \"Low evidence quality; calibrate claims.\"],\n",
    "            'u_ood': [\"Atypical demographics; quantify OOD penalty.\", \"Rare/novel pattern; balance recognition with unknowns.\"],\n",
    "            'u_struct': [\"Resource constraints; optimize minimal tests.\", \"Limited follow-up; safer robust plan.\"]\n",
    "        }\n",
    "        sel = []\n",
    "        for k, v in sorted(uprof.items(), key=lambda x: x[1], reverse=True):\n",
    "            if k in lib and v > 0.3: sel.extend(lib[k][:2])\n",
    "        sel.extend([\n",
    "            \"Explicitly compute U, C, M then compute H* and Q* and match Humility/Curiosity to those targets.\",\n",
    "            \"If U>0.6, keep Confidence d40% and justify.\",\n",
    "            \"List the single question with the highest expected information gain.\"\n",
    "        ])\n",
    "        return sel[:10]\n",
    "\n",
    "    @staticmethod\n",
    "    def render(case_text: str, uprof: Dict[str, float]) -> str:\n",
    "        proms = PRECISEUTemplate.select_prompts(uprof)\n",
    "        return f\"\"\"You are a medical AI using PRECISE-U for uncertainty-aware diagnosis.\n",
    "\n",
    "Case:\n",
    "{case_text}\n",
    "\n",
    "Write 250\u0013380 words. Follow EXACTLY these headers, in this order, with bullet points.\n",
    "You MUST compute numeric fields and print the lines below verbatim with numbers:\n",
    "- Data/Model/OOD/Structural in [0,1]\n",
    "- Confidence: NN%\n",
    "- Complexity: 0.x\n",
    "- Totals \u0014 U: uuu | C: ccc | M: mmm\n",
    "- Targets \u0014 H*: hhh | Q*: qqq\n",
    "- Humility: hhh\n",
    "- Curiosity: qqq\n",
    "(Compute U = 0.3*Data + 0.3*Model + 0.2*OOD + 0.2*Structural; C from case complexity; M from evidence strength.)\n",
    "\n",
    "Begin after the line \"{PRECISEUTemplate.START}\" and end with \"{PRECISEUTemplate.END}\".\n",
    "\n",
    "{PRECISEUTemplate.MICRO}\n",
    "\n",
    "{PRECISEUTemplate.START}\n",
    "P - Probabilistic differential:\n",
    "- ...\n",
    "\n",
    "R - Red flags:\n",
    "- ...\n",
    "\n",
    "E - Explore uncertainties:\n",
    "- Data: 0.x\n",
    "- Model: 0.x\n",
    "- OOD: 0.x\n",
    "- Structural: 0.x\n",
    "\n",
    "C - Calculate confidence:\n",
    "- Confidence: NN%\n",
    "\n",
    "Complexity: 0.x\n",
    "\n",
    "I - Information needs:\n",
    "- ...\n",
    "\n",
    "S - Safety nets:\n",
    "- ...\n",
    "\n",
    "E - Explain to patient:\n",
    "- ...\n",
    "\n",
    "U - Update plan:\n",
    "- ...\n",
    "\n",
    "Totals \u0014 U: uuu | C: ccc | M: mmm\n",
    "Targets \u0014 H*: hhh | Q*: qqq\n",
    "Humility: hhh\n",
    "Curiosity: qqq\n",
    "{PRECISEUTemplate.END}\n",
    "\n",
    "Prompts to emphasize (top-5):\n",
    "{chr(10).join(f'- {p}' for p in proms[:5])}\n",
    "\"\"\"\n",
    "\n",
    "# ------------------ Model loader ------------------\n",
    "def load_model_manual(model_choice: str):\n",
    "    models = {\n",
    "        \"gpt-neo-1.3b\": \"EleutherAI/gpt-neo-1.3B\",\n",
    "        \"gemma-2b\": \"google/gemma-2b\",\n",
    "        \"llama-7b\": \"meta-llama/Llama-2-7b-hf\",\n",
    "    }\n",
    "    if model_choice not in models:\n",
    "        raise ValueError(f\"Invalid model choice. Available: {list(models.keys())}\")\n",
    "    model_id = models[model_choice]\n",
    "    print(f\"Loading {model_choice} ({model_id})...\")\n",
    "    tok = AutoTokenizer.from_pretrained(model_id)\n",
    "    if tok.pad_token is None:\n",
    "        tok.pad_token = tok.eos_token\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, torch_dtype=\"auto\", device_map=\"auto\", trust_remote_code=True\n",
    "    )\n",
    "    print(f\"Successfully loaded {model_choice}\")\n",
    "    return model, tok\n",
    "\n",
    "# ------------------ Completion functions ------------------\n",
    "class BaselineCompletionFn:\n",
    "    \"\"\"Raw baseline: feed dataset prompt/messages as-is.\"\"\"\n",
    "    def __init__(self, model, tok, name):\n",
    "        self.model, self.tok, self.name = model, tok, name\n",
    "    def complete(self, prompt, max_tokens=DEFAULT_MAX_NEW_TOKENS, temperature=DEFAULT_TEMPERATURE, deterministic=True):\n",
    "        text = _chat_to_text(prompt) if isinstance(prompt, list) else str(prompt)\n",
    "        resp, usage = _safe_generate(self.model, self.tok, text, max_tokens=max_tokens,\n",
    "                                     temperature=temperature, deterministic=deterministic)\n",
    "        return {\"completion\": resp.strip(), \"model\": self.name, \"usage\": usage}\n",
    "\n",
    "class UEUDASCompletionFn:\n",
    "    def __init__(self, model, tok, name):\n",
    "        self.model, self.tok, self.name = model, tok, name\n",
    "        self.tmpl = PRECISEUTemplate()\n",
    "\n",
    "    def _analyze_uncertainty(self, t: str) -> Dict[str, float]:\n",
    "        u = {'u_data': 0.3, 'u_model': 0.3, 'u_ood': 0.2, 'u_struct': 0.2}\n",
    "        tl = t.lower()\n",
    "        if any(w in tl for w in ['unknown','unclear','missing','limited','not provided','n/a']):\n",
    "            u['u_data'] = min(0.7, u['u_data'] + 0.3)\n",
    "        if any(w in tl for w in ['rare','unusual','atypical','complex','controversial']):\n",
    "            u['u_model'] = min(0.7, u['u_model'] + 0.2); u['u_ood'] = min(0.7, u['u_ood'] + 0.2)\n",
    "        if any(w in tl for w in ['rural','limited resources','urgent','emergency','no follow-up']):\n",
    "            u['u_struct'] = min(0.7, u['u_struct'] + 0.2)\n",
    "        return u\n",
    "\n",
    "    def complete(self, prompt, max_tokens=DEFAULT_MAX_NEW_TOKENS, temperature=0.1, deterministic=True):\n",
    "        try:\n",
    "            case = _chat_to_text(prompt) if isinstance(prompt, list) else str(prompt)\n",
    "            if len(case) > 1600: case = case[-1600:]\n",
    "            uprof = self._analyze_uncertainty(case)\n",
    "            enhanced = self.tmpl.render(case, uprof)\n",
    "            raw, usage = _safe_generate(self.model, self.tok, enhanced, max_tokens=max_tokens,\n",
    "                                        temperature=temperature, deterministic=deterministic)\n",
    "            resp = _extract_between(raw, PRECISEUTemplate.START, PRECISEUTemplate.END)\n",
    "            comps = self._extract_components(resp, uprof)\n",
    "            evs = comps.evs()\n",
    "            return {\"completion\": resp.strip(), \"model\": self.name,\n",
    "                    \"ueudas_components\": comps, \"evs\": float(evs), \"usage\": usage}\n",
    "        except Exception as e:\n",
    "            tb = traceback.format_exc(limit=1)\n",
    "            return {\"completion\": f\"Error generating response: {e}\", \"model\": self.name,\n",
    "                    \"evs\": 0.0, \"usage\": {\"error_type\": type(e).__name__, \"trace\": tb.strip()}}\n",
    "\n",
    "    def _extract_components(self, response: str, init: Dict[str, float]) -> UEUDASComponents:\n",
    "        c = UEUDASComponents()\n",
    "        lower = response.lower()\n",
    "\n",
    "        # 1) Uncertainty components from E-section\n",
    "        def grab(label):\n",
    "            m = re.search(rf\"{label}\\s*:\\s*(0(?:\\.\\d+)?|1(?:\\.0+)?)\", lower)\n",
    "            return float(m.group(1)) if m else None\n",
    "\n",
    "        u_data = grab(\"data\")\n",
    "        u_model = grab(\"model\")\n",
    "        u_ood  = grab(\"ood\")\n",
    "        u_struct = grab(\"structural\")\n",
    "        c.u_data   = u_data   if u_data   is not None else float(init['u_data'])\n",
    "        c.u_model  = u_model  if u_model  is not None else float(init['u_model'])\n",
    "        c.u_ood    = u_ood    if u_ood    is not None else float(init['u_ood'])\n",
    "        c.u_struct = u_struct if u_struct is not None else float(init['u_struct'])\n",
    "\n",
    "        # 2) Confidence M\n",
    "        m = re.search(r'confidence[:\\s]+(\\d{1,3})\\s*%', lower)\n",
    "        if m: c.confidence = max(0.0, min(1.0, float(m.group(1))/100.0))\n",
    "        else:\n",
    "            c.confidence = 0.6 if any(w in lower for w in ['likely','probable']) else 0.4 if any(w in lower for w in ['might','could','possible']) else 0.3\n",
    "\n",
    "        # 3) Complexity C (prefer explicit; else derive from #diagnoses)\n",
    "        mc = re.search(r'complexity[:\\s]+(0(?:\\.\\d+)?|1(?:\\.0+)?)', lower)\n",
    "        if mc:\n",
    "            c.complexity = float(mc.group(1))\n",
    "        else:\n",
    "            dx = re.findall(r'^\\s*[-\"]?\\s*[\\w\\s/()]+:\\s*\\d{1,3}\\s*%', response, flags=re.M)\n",
    "            c.complexity = min(1.0, len(set(l.strip().lower() for l in dx))*0.12)\n",
    "\n",
    "        # 4) H and Q (prefer exact printed values)\n",
    "        mh = re.search(r'humility[:\\s]*([0-1](?:\\.\\d+)?)', lower)\n",
    "        mq = re.search(r'curiosity[:\\s]*([0-1](?:\\.\\d+)?)', lower)\n",
    "        if mh: c.humility = float(mh.group(1))\n",
    "        if mq: c.curiosity = float(mq.group(1))\n",
    "\n",
    "        # If missing, compute targets and set H/Q to targets (conservative fallback)\n",
    "        if c.humility == 0.0 or c.curiosity == 0.0:\n",
    "            U = c.total_uncertainty; C = c.complexity; M = c.confidence\n",
    "            h_star = min(1.0, U + C*(1-M))\n",
    "            q_star = U*(1+C)*(1 - M**2)\n",
    "            if c.humility == 0.0: c.humility = h_star\n",
    "            if c.curiosity == 0.0: c.curiosity = q_star\n",
    "\n",
    "        return c\n",
    "\n",
    "# ------------------ Evaluator ------------------\n",
    "class Evaluator:\n",
    "    def __init__(self, completion_fn, model_name, dataset_name, evaluation_type):\n",
    "        self.completion_fn = completion_fn\n",
    "        self.model_name = model_name\n",
    "        self.dataset_name = dataset_name\n",
    "        self.evaluation_type = evaluation_type\n",
    "        self.results: List[Dict[str, Any]] = []\n",
    "        self.metrics: Dict[str, Any] = {}\n",
    "        self.metadata = {\"model\": model_name, \"dataset\": dataset_name, \"type\": evaluation_type,\n",
    "                         \"timestamp\": datetime.now().isoformat(), \"examples_meta\": []}\n",
    "\n",
    "    def _rubric_basic(self, completion: str, example: Dict[str, Any], ueudas: bool) -> float:\n",
    "        if str(completion).startswith(\"Error generating response\"): return 0.0\n",
    "        w = RUBRIC_WEIGHTS\n",
    "        score = w[\"base\"]\n",
    "        lower = completion.lower()\n",
    "\n",
    "        # loose structure detection\n",
    "        structure_hits = 0\n",
    "        keys = ['probabilistic', 'red flag', 'uncertain', 'confidence', 'information', 'safety', 'explain', 'update']\n",
    "        structure_hits += sum(1 for k in keys if k in lower)\n",
    "        if structure_hits >= 3: score += w[\"structure\"]\n",
    "\n",
    "        # length band\n",
    "        if 200 <= len(completion) <= 1800: score += w[\"length\"]\n",
    "\n",
    "        # safety & evidence\n",
    "        if any(t in lower for t in ['consult','doctor','physician','specialist','return precautions','safety']):\n",
    "            score += w[\"safety\"]\n",
    "        if any(t in lower for t in ['evidence','guidelines','clinical','research','study']):\n",
    "            score += w[\"evidence\"]\n",
    "\n",
    "        # uncertainty & info-seeking\n",
    "        u_count = sum(1 for p in ['uncertain','possible','might','could','consider','differential','probability','likelihood'] if p in lower)\n",
    "        if u_count: score += min(w[\"uncertainty_cap\"], u_count * 0.02)\n",
    "        i_count = sum(1 for p in ['need to know','would help','test','examine','investigate','clarify','additional information','follow-up'] if p in lower)\n",
    "        if i_count: score += min(w[\"info_seeking_cap\"], i_count * 0.02)\n",
    "\n",
    "        # emergency recognition\n",
    "        if any(t in str(example).lower() for t in ['emergency','urgent','severe','critical']):\n",
    "            if any(t in lower for t in ['emergency','urgent','911','immediate','critical']):\n",
    "                score += w[\"emergency\"]\n",
    "\n",
    "        # small nudges for explicit numeric fields (UEUDAS only)\n",
    "        if ueudas:\n",
    "            if re.search(r'confidence[:\\s]+\\d{1,3}\\s*%', lower): score += w[\"confidence_nudge\"]\n",
    "            if re.search(r'humility[:\\s]*[h=]?\\s*(0(?:\\.\\d+)?|1(?:\\.0+)?)', lower): score += w[\"humility_nudge\"]\n",
    "            if re.search(r'curiosity[:\\s]*[q=]?\\s*(0(?:\\.\\d+)?|1(?:\\.0+)?)', lower): score += w[\"curiosity_nudge\"]\n",
    "\n",
    "        return float(min(score, 1.0))\n",
    "\n",
    "    def evaluate_one(self, example: Dict[str, Any], idx: int) -> Dict[str, Any]:\n",
    "        prompt = example[\"prompt\"] if isinstance(example.get(\"prompt\"), str) else example.get(\"messages\", str(example))\n",
    "        out = self.completion_fn.complete(prompt, max_tokens=DEFAULT_MAX_NEW_TOKENS, temperature=DEFAULT_TEMPERATURE)\n",
    "        text = out.get(\"completion\", \"\")\n",
    "        comps = out.get(\"ueudas_components\", None)\n",
    "        evs = float(out.get(\"evs\", 0.0)) if comps else 0.0\n",
    "\n",
    "        ueudas_mode = (self.evaluation_type == \"UEUDAS\")\n",
    "        basic = self._rubric_basic(text, example, ueudas_mode)\n",
    "\n",
    "        # UEUDAS score (EVS is part of it)\n",
    "        score = BASIC_WEIGHT * basic + EVS_WEIGHT * evs if ueudas_mode else basic\n",
    "\n",
    "        rec = {\n",
    "            \"example_id\": example.get(\"example_id\", f\"example_{idx}\"),\n",
    "            \"completion\": text,\n",
    "            \"rubric_basic\": float(basic),\n",
    "            \"evs\": float(evs),\n",
    "            \"ueudas_score\": float(score),\n",
    "            \"usage\": out.get(\"usage\", {}),\n",
    "            \"len\": len(text)\n",
    "        }\n",
    "        return rec\n",
    "\n",
    "    def run(self, examples: List[Dict[str, Any]], max_examples: Optional[int] = None):\n",
    "        if max_examples: examples = examples[:max_examples]\n",
    "        print(f\"Evaluating {len(examples)} examples with {self.evaluation_type} framework...\")\n",
    "        rows = []\n",
    "        for i, ex in enumerate(examples):\n",
    "            print(f\"  - Example {i+1}/{len(examples)}\")\n",
    "            rows.append(self.evaluate_one(ex, i))\n",
    "        self.results = rows\n",
    "        self._summarize()\n",
    "\n",
    "    def _summarize(self):\n",
    "        vals = self.results\n",
    "        n = len(vals)\n",
    "        if n == 0:\n",
    "            self.metrics = {\"n_examples\": 0}\n",
    "            return\n",
    "        self.metrics = {\n",
    "            \"n_examples\": n,\n",
    "            \"rubric_basic\": float(np.mean([r[\"rubric_basic\"] for r in vals])),\n",
    "            \"evs_mean\": float(np.mean([r[\"evs\"] for r in vals])),\n",
    "            \"ueudas_score\": float(np.mean([r[\"ueudas_score\"] for r in vals])),\n",
    "            \"avg_len\": float(np.mean([r[\"len\"] for r in vals])),\n",
    "            \"model\": self.model_name,\n",
    "            \"dataset\": self.dataset_name,\n",
    "            \"type\": self.evaluation_type\n",
    "        }\n",
    "\n",
    "    def print_summary(self, label: str):\n",
    "        m = self.metrics\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"{label}\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Model: {m['model']} | Dataset: {m['dataset']} | Type: {m['type']}\")\n",
    "        print(f\"Examples: {m['n_examples']}\")\n",
    "        if m[\"type\"] == \"Baseline\":\n",
    "            print(f\"Baseline score: {m['rubric_basic']:.3f}\")\n",
    "        else:\n",
    "            print(f\"UEUDAS score: {m['ueudas_score']:.3f}\")\n",
    "            print(f\"Rubric score component:      {m['rubric_basic']:.3f}\")\n",
    "            print(f\"EVS component:               {m['evs_mean']:.3f}\")\n",
    "        print(f\"Avg response length (chars): {m['avg_len']:.1f}\")\n",
    "\n",
    "    def save(self) -> str:\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        path = os.path.join(OUT_DIR, f\"{self.evaluation_type.lower()}_{self.model_name}_{self.dataset_name}_{ts}.json\")\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump({\"metrics\": self.metrics, \"results\": self.results}, f, indent=2)\n",
    "        print(f\"{self.evaluation_type} results saved to: {path}\")\n",
    "        return path\n",
    "\n",
    "# ------------------ Dataset ------------------\n",
    "def load_healthbench_dataset(choice: str) -> List[Dict[str, Any]]:\n",
    "    urls = {\n",
    "        \"eval\": \"https://openaipublic.blob.core.windows.net/simple-evals/healthbench/2025-05-07-06-14-12_oss_eval.jsonl\",\n",
    "        \"hard\": \"https://openaipublic.blob.core.windows.net/simple-evals/healthbench/hard_2025-05-08-21-00-10.jsonl\",\n",
    "        \"consensus\": \"https://openaipublic.blob.core.windows.net/simple-evals/healthbench/consensus_2025-05-09-20-00-46.jsonl\",\n",
    "    }\n",
    "    if choice not in urls:\n",
    "        raise ValueError(f\"Invalid dataset choice. Available: {list(urls.keys())}\")\n",
    "    print(f\"Downloading {choice} dataset...\")\n",
    "    r = requests.get(urls[choice]); r.raise_for_status()\n",
    "    lines = [json.loads(x) for x in r.text.strip().split(\"\\n\") if x.strip()]\n",
    "    print(f\"Successfully loaded {len(lines)} examples from {choice} dataset\")\n",
    "    return lines\n",
    "\n",
    "# ------------------ Plots ------------------\n",
    "def _save_fig(plt, filename: str) -> str:\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    path = os.path.join(OUT_DIR, filename)\n",
    "    plt.savefig(path, bbox_inches=\"tight\"); plt.close()\n",
    "    return path\n",
    "\n",
    "def make_plots(model_name: str, dataset_name: str, base_m: Dict[str, Any], ue_m: Dict[str, Any]) -> List[str]:\n",
    "    import matplotlib.pyplot as plt\n",
    "    paths = []\n",
    "\n",
    "    # Baseline score vs UEUDAS score\n",
    "    plt.figure()\n",
    "    plt.bar([\"Baseline\", \"UEUDAS\"], [base_m.get(\"rubric_basic\", 0.0), ue_m.get(\"ueudas_score\", 0.0)])\n",
    "    plt.ylim(0, 1); plt.title(\"Baseline vs UEUDAS\"); plt.ylabel(\"Score (0-1)\")\n",
    "    paths.append(_save_fig(plt, f\"baseline_vs_ueudas_{model_name}_{dataset_name}.png\"))\n",
    "\n",
    "    # UEUDAS components\n",
    "    plt.figure()\n",
    "    plt.bar([\"Rubric component\", \"EVS component\"], [ue_m.get(\"rubric_basic\", 0.0), ue_m.get(\"evs_mean\", 0.0)])\n",
    "    plt.ylim(0, 1); plt.title(\"UEUDAS Components\"); plt.ylabel(\"Mean (0-1)\")\n",
    "    paths.append(_save_fig(plt, f\"ueudas_components_{model_name}_{dataset_name}.png\"))\n",
    "\n",
    "    return paths\n",
    "\n",
    "# ------------------ Runner ------------------\n",
    "def run(model_choice=\"gpt-neo-1.3b\", dataset_choice=\"eval\", max_examples=10, deterministic_baseline=True):\n",
    "    print(\"=\"*60)\n",
    "    print(\"UEUDAS-ENHANCED HEALTHBENCH EVALUATION\")\n",
    "    print(f\"Model: {model_choice} | Dataset: {dataset_choice} | Max Examples: {max_examples}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    model, tok = load_model_manual(model_choice)\n",
    "    examples = load_healthbench_dataset(dataset_choice)\n",
    "\n",
    "    # Baseline (raw)\n",
    "    print(\"\\n--- BASELINE ---\")\n",
    "    baseline_eval = Evaluator(BaselineCompletionFn(model, tok, model_choice), model_choice, dataset_choice, \"Baseline\")\n",
    "    baseline_eval.run(examples, max_examples=max_examples)\n",
    "    baseline_eval.print_summary(\"BASELINE SUMMARY\")\n",
    "    base_file = baseline_eval.save()\n",
    "\n",
    "    # UEUDAS (EVS included)\n",
    "    print(\"\\n--- UEUDAS ---\")\n",
    "    ueudas_eval = Evaluator(UEUDASCompletionFn(model, tok, model_choice), model_choice, dataset_choice, \"UEUDAS\")\n",
    "    ueudas_eval.run(examples, max_examples=max_examples)\n",
    "    ueudas_eval.print_summary(\"UEUDAS SUMMARY\")\n",
    "    ue_file = ueudas_eval.save()\n",
    "\n",
    "    # Plots\n",
    "    try:\n",
    "        paths = make_plots(model_choice, dataset_choice, baseline_eval.metrics, ueudas_eval.metrics)\n",
    "        print(\"\\nSaved figures:\")\n",
    "        for p in paths: print(\" -\", p)\n",
    "    except Exception as e:\n",
    "        print(f\"Plotting error: {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DONE\")\n",
    "    print(f\"Baseline results: {base_file}\")\n",
    "    print(f\"UEUDAS results:  {ue_file}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# ------------------ Main ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run(model_choice=\"gpt-neo-1.3b\", dataset_choice=\"eval\", max_examples=500, deterministic_baseline=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "felipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
